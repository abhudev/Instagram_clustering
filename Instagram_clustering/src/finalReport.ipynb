{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nie_Pwv5IJJo"
   },
   "source": [
    "# Unsupervised learning techniques on Instagram data\n",
    "\n",
    "For our Practical Data Science final project we scraped Instagram data to examine different ways in people put forth their views on this platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-84WIi1IJJq"
   },
   "source": [
    "## Motivation\n",
    "\n",
    "Instagram is widely used to post content by a plethora of users like the general public, businesses, celebrities, eductaion and scientific organziations around the world. A common way of posting content on this social media platform to increase the popularity of the posts is by using hashtags. Users have different sentiments and strategies to use these hashtags and often times they only relate to the post content tangentially. Many times users randomly use 'trending' hashtags to accomplish their goal of engaging more users through their posts.\n",
    "\n",
    "Through this project we wanted to analyze the behavior of users by analyzing how images are posted on instagram paired with different hashtags and captions. While captions are written in an attempt to describe the post, hashtags are used to add value to the description and also gain popularity. This is achieved by clustering the posts using unsupervised learning techniques and clustering the content within each cluster again to define sub-groups of posts using hashtags and sentence embeddings that are derived from captions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YLKHwjZ-IJJr"
   },
   "source": [
    "## Content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gta48YIIJJs"
   },
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Data](#Data)\n",
    "3. [Data Cleaning](#Data-Cleaning)\n",
    "4. [Modelling and Visualizations](#Modelling-and-Visualizations)\n",
    "5. [Results](#Results)\n",
    "6. [FutureWork](#FutureWork)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3P29ONJIJJt"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "Instagram's content can be analyzed to derive key insights about user behavior on he platform. Within the scope of our study we focus on a specific domain to extract data and analyze it. Our reference case refers to how people post content with the hashtag 'cliamtechange'. Using only images (no data related to stories or video posts were analyzed within the scope of our project), the associated hashtags, and captions of the post we attempted to do a cluster within cluster analysi to classify the data within groups and sub-groups anc visualize them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oIIhJPzyIJJu"
   },
   "source": [
    "### Data\n",
    "\n",
    "The data used in the project was scraped using 'Igram Scraper' (https://github.com/realsirjoe/instagram-scraper) instead of the official Instagram API key. The official API key gives access to only limited Instagram data and thus the alternative scraper tool was used. The scraper was used to pull posts which used the hashtag 'climatechange'. With a break of 1.5 seconds between each request to ensure that our IP address is not blocked by Instagram, 10000 posts were extracted on 28th Novemeber 2019. These 10000 posts included both images and video posts and spanned within the time frame of 26th November 2019 - 28th November 2019.\n",
    "\n",
    "Due to security and privacy policies defined by Instagram, there is no best method to pull \"large\" amounts of data from Instagram in real time. The scraper tool used in this project was the best option to extract data related to images, i.e. the image itself, the url to the post, the timestamp, associated caption and hashtag to the post, location of post (if provided by the user), total number of organic likes, total of organic + sponsored likes, and  total number of comments. \n",
    "\n",
    "An attempt was made to extract 25000 and 50000 posts using this scraper, but beyond 10000 posts our requests to the Instagram failed to gather any content. In future work, an attempt can be made to use a scraper of write one from scratch to extract more data, but within the scope of our project we were successful in deriving criticall insights from the 10000 posts collected.\n",
    "\n",
    "Additionally, attempting to extract images along with its meta-data (hashtags, captions, likes etc.) consumed a lot of time, which resulted in multiple time-out errors, and thus the images were extracted separately after the meta data was collected using the 'Igram scraper'. This was completed by using the post links collected in the meta-data to separately extract all the images by preserving the order. It is important to note that Instagram introduced a new feature where multiple images can be posted in a single post, but within the time-frame for our study, while scraping the images, only the first image of the post was considered for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUojWCg-IJJv"
   },
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "\n",
    "from igramscraper.instagram import Instagram # pylint: disable=no-name-in-module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lmTyKnrfIJJz",
    "outputId": "5cdfb8e9-2c44-41d9-dd69-736f6cdf9f57"
   },
   "outputs": [],
   "source": [
    "# Scraping the data\n",
    "\n",
    "instagram = Instagram(sleep_between_requests=1.5)\n",
    "\n",
    "medias = instagram.get_medias_by_tag('climatechange', count=10000)\n",
    "\n",
    "fp = open(\"climate_igram_10k.txt\", \"w\")\n",
    "\n",
    "for media in medias:\n",
    "    print(media, file=fp)\n",
    "    print('Account info:', file=fp)\n",
    "    account = media.owner\n",
    "    print('Id', account.identifier, file=fp)\n",
    "    # print('Username', account.username)\n",
    "    # print('Full Name', account.full_name)\n",
    "    # print('Profile Pic Url', account.get_profile_picture_url_hd())\n",
    "    print('--------------------------------------------------', file=fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBLMpHKgIJJ6",
    "outputId": "b54c533c-dd86-4c28-9774-8f665a9d6bbe"
   },
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--infile\")\n",
    "# parser.add_argument(\"--outfile\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "fp = open(\"climate_igram_10k.txt\")\n",
    "\n",
    "hdr_to_key = {\n",
    "    \"'Id:\": \"media_id\",\n",
    "    \"Shortcode:\": \"shortcode\",\n",
    "    \"Created at:\": \"timestamp\",\n",
    "    \"Caption:\": \"caption\",\n",
    "    \"Number of comments:\": \"num_comments\",\n",
    "    \"Number of likes:\": \"num_likes\",\n",
    "    \"Link:\": \"post_link\",\n",
    "    \"Hig res image:\": \"media_link\",\n",
    "    \"Media type:\": \"media_type\",\n",
    "    \"Id\": \"account_id\"}\n",
    "\n",
    "metadata = []\n",
    "image_info = {}\n",
    "caption_str = \"\"\n",
    "reading_caption = 0\n",
    "num_media =  0\n",
    "\n",
    "# Hashtags regex - taken from rarcega/instagram-scraper\n",
    "hashtag_regex_string = r\"(?<!&)#(\\w+|(?:[\\xA9\\xAE\\u203C\\u2049\\u2122\\u2139\\u2194-\\u2199\\u21A9\\u21AA\\u231A\\u231B\\u2328\\u2388\\u23CF\\u23E9-\\u23F3\\u23F8-\\u23FA\\u24C2\\u25AA\\u25AB\\u25B6\\u25C0\\u25FB-\\u25FE\\u2600-\\u2604\\u260E\\u2611\\u2614\\u2615\\u2618\\u261D\\u2620\\u2622\\u2623\\u2626\\u262A\\u262E\\u262F\\u2638-\\u263A\\u2648-\\u2653\\u2660\\u2663\\u2665\\u2666\\u2668\\u267B\\u267F\\u2692-\\u2694\\u2696\\u2697\\u2699\\u269B\\u269C\\u26A0\\u26A1\\u26AA\\u26AB\\u26B0\\u26B1\\u26BD\\u26BE\\u26C4\\u26C5\\u26C8\\u26CE\\u26CF\\u26D1\\u26D3\\u26D4\\u26E9\\u26EA\\u26F0-\\u26F5\\u26F7-\\u26FA\\u26FD\\u2702\\u2705\\u2708-\\u270D\\u270F\\u2712\\u2714\\u2716\\u271D\\u2721\\u2728\\u2733\\u2734\\u2744\\u2747\\u274C\\u274E\\u2753-\\u2755\\u2757\\u2763\\u2764\\u2795-\\u2797\\u27A1\\u27B0\\u27BF\\u2934\\u2935\\u2B05-\\u2B07\\u2B1B\\u2B1C\\u2B50\\u2B55\\u3030\\u303D\\u3297\\u3299]|\\uD83C[\\uDC04\\uDCCF\\uDD70\\uDD71\\uDD7E\\uDD7F\\uDD8E\\uDD91-\\uDD9A\\uDE01\\uDE02\\uDE1A\\uDE2F\\uDE32-\\uDE3A\\uDE50\\uDE51\\uDF00-\\uDF21\\uDF24-\\uDF93\\uDF96\\uDF97\\uDF99-\\uDF9B\\uDF9E-\\uDFF0\\uDFF3-\\uDFF5\\uDFF7-\\uDFFF]|\\uD83D[\\uDC00-\\uDCFD\\uDCFF-\\uDD3D\\uDD49-\\uDD4E\\uDD50-\\uDD67\\uDD6F\\uDD70\\uDD73-\\uDD79\\uDD87\\uDD8A-\\uDD8D\\uDD90\\uDD95\\uDD96\\uDDA5\\uDDA8\\uDDB1\\uDDB2\\uDDBC\\uDDC2-\\uDDC4\\uDDD1-\\uDDD3\\uDDDC-\\uDDDE\\uDDE1\\uDDE3\\uDDEF\\uDDF3\\uDDFA-\\uDE4F\\uDE80-\\uDEC5\\uDECB-\\uDED0\\uDEE0-\\uDEE5\\uDEE9\\uDEEB\\uDEEC\\uDEF0\\uDEF3]|\\uD83E[\\uDD10-\\uDD18\\uDD80-\\uDD84\\uDDC0]|(?:0\\u20E3|1\\u20E3|2\\u20E3|3\\u20E3|4\\u20E3|5\\u20E3|6\\u20E3|7\\u20E3|8\\u20E3|9\\u20E3|#\\u20E3|\\\\*\\u20E3|\\uD83C(?:\\uDDE6\\uD83C(?:\\uDDEB|\\uDDFD|\\uDDF1|\\uDDF8|\\uDDE9|\\uDDF4|\\uDDEE|\\uDDF6|\\uDDEC|\\uDDF7|\\uDDF2|\\uDDFC|\\uDDE8|\\uDDFA|\\uDDF9|\\uDDFF|\\uDDEA)|\\uDDE7\\uD83C(?:\\uDDF8|\\uDDED|\\uDDE9|\\uDDE7|\\uDDFE|\\uDDEA|\\uDDFF|\\uDDEF|\\uDDF2|\\uDDF9|\\uDDF4|\\uDDE6|\\uDDFC|\\uDDFB|\\uDDF7|\\uDDF3|\\uDDEC|\\uDDEB|\\uDDEE|\\uDDF6|\\uDDF1)|\\uDDE8\\uD83C(?:\\uDDF2|\\uDDE6|\\uDDFB|\\uDDEB|\\uDDF1|\\uDDF3|\\uDDFD|\\uDDF5|\\uDDE8|\\uDDF4|\\uDDEC|\\uDDE9|\\uDDF0|\\uDDF7|\\uDDEE|\\uDDFA|\\uDDFC|\\uDDFE|\\uDDFF|\\uDDED)|\\uDDE9\\uD83C(?:\\uDDFF|\\uDDF0|\\uDDEC|\\uDDEF|\\uDDF2|\\uDDF4|\\uDDEA)|\\uDDEA\\uD83C(?:\\uDDE6|\\uDDE8|\\uDDEC|\\uDDF7|\\uDDEA|\\uDDF9|\\uDDFA|\\uDDF8|\\uDDED)|\\uDDEB\\uD83C(?:\\uDDF0|\\uDDF4|\\uDDEF|\\uDDEE|\\uDDF7|\\uDDF2)|\\uDDEC\\uD83C(?:\\uDDF6|\\uDDEB|\\uDDE6|\\uDDF2|\\uDDEA|\\uDDED|\\uDDEE|\\uDDF7|\\uDDF1|\\uDDE9|\\uDDF5|\\uDDFA|\\uDDF9|\\uDDEC|\\uDDF3|\\uDDFC|\\uDDFE|\\uDDF8|\\uDDE7)|\\uDDED\\uD83C(?:\\uDDF7|\\uDDF9|\\uDDF2|\\uDDF3|\\uDDF0|\\uDDFA)|\\uDDEE\\uD83C(?:\\uDDF4|\\uDDE8|\\uDDF8|\\uDDF3|\\uDDE9|\\uDDF7|\\uDDF6|\\uDDEA|\\uDDF2|\\uDDF1|\\uDDF9)|\\uDDEF\\uD83C(?:\\uDDF2|\\uDDF5|\\uDDEA|\\uDDF4)|\\uDDF0\\uD83C(?:\\uDDED|\\uDDFE|\\uDDF2|\\uDDFF|\\uDDEA|\\uDDEE|\\uDDFC|\\uDDEC|\\uDDF5|\\uDDF7|\\uDDF3)|\\uDDF1\\uD83C(?:\\uDDE6|\\uDDFB|\\uDDE7|\\uDDF8|\\uDDF7|\\uDDFE|\\uDDEE|\\uDDF9|\\uDDFA|\\uDDF0|\\uDDE8)|\\uDDF2\\uD83C(?:\\uDDF4|\\uDDF0|\\uDDEC|\\uDDFC|\\uDDFE|\\uDDFB|\\uDDF1|\\uDDF9|\\uDDED|\\uDDF6|\\uDDF7|\\uDDFA|\\uDDFD|\\uDDE9|\\uDDE8|\\uDDF3|\\uDDEA|\\uDDF8|\\uDDE6|\\uDDFF|\\uDDF2|\\uDDF5|\\uDDEB)|\\uDDF3\\uD83C(?:\\uDDE6|\\uDDF7|\\uDDF5|\\uDDF1|\\uDDE8|\\uDDFF|\\uDDEE|\\uDDEA|\\uDDEC|\\uDDFA|\\uDDEB|\\uDDF4)|\\uDDF4\\uD83C\\uDDF2|\\uDDF5\\uD83C(?:\\uDDEB|\\uDDF0|\\uDDFC|\\uDDF8|\\uDDE6|\\uDDEC|\\uDDFE|\\uDDEA|\\uDDED|\\uDDF3|\\uDDF1|\\uDDF9|\\uDDF7|\\uDDF2)|\\uDDF6\\uD83C\\uDDE6|\\uDDF7\\uD83C(?:\\uDDEA|\\uDDF4|\\uDDFA|\\uDDFC|\\uDDF8)|\\uDDF8\\uD83C(?:\\uDDFB|\\uDDF2|\\uDDF9|\\uDDE6|\\uDDF3|\\uDDE8|\\uDDF1|\\uDDEC|\\uDDFD|\\uDDF0|\\uDDEE|\\uDDE7|\\uDDF4|\\uDDF8|\\uDDED|\\uDDE9|\\uDDF7|\\uDDEF|\\uDDFF|\\uDDEA|\\uDDFE)|\\uDDF9\\uD83C(?:\\uDDE9|\\uDDEB|\\uDDFC|\\uDDEF|\\uDDFF|\\uDDED|\\uDDF1|\\uDDEC|\\uDDF0|\\uDDF4|\\uDDF9|\\uDDE6|\\uDDF3|\\uDDF7|\\uDDF2|\\uDDE8|\\uDDFB)|\\uDDFA\\uD83C(?:\\uDDEC|\\uDDE6|\\uDDF8|\\uDDFE|\\uDDF2|\\uDDFF)|\\uDDFB\\uD83C(?:\\uDDEC|\\uDDE8|\\uDDEE|\\uDDFA|\\uDDE6|\\uDDEA|\\uDDF3)|\\uDDFC\\uD83C(?:\\uDDF8|\\uDDEB)|\\uDDFD\\uD83C\\uDDF0|\\uDDFE\\uD83C(?:\\uDDF9|\\uDDEA)|\\uDDFF\\uD83C(?:\\uDDE6|\\uDDF2|\\uDDFC))))[\\ufe00-\\ufe0f\\u200d]?)+\"\n",
    "\n",
    "for l in fp:\n",
    "    num_media += 1\n",
    "    line = l.lstrip()\n",
    "    # else\n",
    "    \n",
    "    if(reading_caption == 1 and (not line.startswith(\"Number of comments:\"))):\n",
    "        caption_str += line\n",
    "        continue\n",
    "    if(line.startswith(\"Media Info:\")):\n",
    "        pass\n",
    "    elif(line.startswith(\"'Id:\")):\n",
    "        hdr_str = \"'Id:\"\n",
    "        line = line.strip(hdr_str).lstrip()\n",
    "        image_info[hdr_to_key[hdr_str]] = int(line.strip())\n",
    "    elif(line.startswith(\"Shortcode:\")):\n",
    "        hdr_str = \"Shortcode:\"\n",
    "        line = line.strip(hdr_str).lstrip()\n",
    "        image_info[hdr_to_key[hdr_str]] = line.strip()\n",
    "    elif(line.startswith(\"Created at:\")):\n",
    "        hdr_str = \"Created at:\"\n",
    "        line = line.strip(hdr_str).lstrip()\n",
    "        image_info[hdr_to_key[hdr_str]] = int(line.strip())\n",
    "    elif(line.startswith(\"Caption:\")):\n",
    "        if(reading_caption == 1):\n",
    "            caption_str += line\n",
    "            continue\n",
    "        hdr_str = \"Caption:\"\n",
    "        reading_caption = 1\n",
    "        line = line.strip(hdr_str).lstrip()\n",
    "        caption_str += line\n",
    "    elif(line.startswith(\"Number of comments:\")):\n",
    "        reading_caption = 0\n",
    "        image_info[\"caption\"] = caption_str\n",
    "        image_info[\"hashtags\"] = re.findall(hashtag_regex_string, caption_str, re.UNICODE)\n",
    "        image_info[\"hashtags\"] = list(set(image_info[\"hashtags\"]))\n",
    "        caption_str = \"\"\n",
    "        hdr_str = \"Number of comments:\"\n",
    "        line = line.strip(hdr_str).lstrip()\n",
    "        image_info[hdr_to_key[hdr_str]] = int(line.strip())\n",
    "    elif(line.startswith(\"Number of likes:\")):\n",
    "        hdr_str = \"Number of likes:\"\n",
    "        line = line.strip(hdr_str).lstrip()\n",
    "        image_info[hdr_to_key[hdr_str]] = int(line.strip())\n",
    "    elif(line.startswith(\"Link:\")):\n",
    "        hdr_str = \"Link:\"\n",
    "        line = line.strip(hdr_str).lstrip()\n",
    "        image_info[hdr_to_key[hdr_str]] = line.strip()\n",
    "    elif(line.startswith(\"Hig res image:\")):\n",
    "        hdr_str = \"Hig res image:\"\n",
    "        line = line.strip(hdr_str).lstrip()\n",
    "        image_info[hdr_to_key[hdr_str]] = line.strip()\n",
    "    elif(line.startswith(\"Media type:\")):\n",
    "        hdr_str = \"Media type:\"\n",
    "        line = line.strip(\"Media\").lstrip().strip(\"type:\").lstrip()\n",
    "        image_info[hdr_to_key[hdr_str]] = line.strip()\n",
    "    elif(line.startswith(\"Account info:\")):\n",
    "        pass\n",
    "    elif(line.startswith(\"Id\")):\n",
    "        hdr_str = \"Id\"\n",
    "        line = line.strip(hdr_str).lstrip()\n",
    "        image_info[hdr_to_key[hdr_str]] = int(line.strip())\n",
    "    elif(line.startswith(\"--------------------------------------------------\")):\n",
    "        metadata.append(image_info)\n",
    "        image_info = {}\t\n",
    "\n",
    "fp.close()\n",
    "\n",
    "with open(\"climate_igram_10k.json\", 'w') as outfile:\n",
    "    images_json = {\"media_metadata\": metadata}\n",
    "    json.dump(images_json, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5b7nwudIJJ-",
    "outputId": "f1d437ba-1b0d-4c5f-e0e1-73a422512e23"
   },
   "outputs": [],
   "source": [
    "# Get Image data for the meta-data collected\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--jsonfile')\n",
    "# parser.add_argument('--outfile')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "fp = open(\"climate_igram_10k.json\", 'r')\n",
    "\n",
    "media_json = json.load(fp)\n",
    "\n",
    "img_links = []\n",
    "\n",
    "for media in media_json[\"media_metadata\"]:\n",
    "    if(media[\"media_type\"] == \"image\"):\n",
    "        img_links.append(media[\"media_link\"])\n",
    "\n",
    "fp.close()\n",
    "\n",
    "with open(\"IMG_climate_igram_10k.json\", 'w') as fo:\n",
    "    links_json = {\"img_links\": img_links}\n",
    "    json.dump(links_json, fo, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraper \n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "\n",
    "# img_links - JSON file containing list of image links\n",
    "# out_dir - directory where images are stored\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--img_links')\n",
    "# parser.add_argument('--out_dir')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "img_links = []\n",
    "\n",
    "if(\"images_climate_10k\" is None):\n",
    "    exit()\n",
    "\n",
    "with open(\"IMG_climate_igram_10k.json\", 'r') as fin:\n",
    "    img_json = json.load(fin)\n",
    "    img_links = img_json[\"img_links\"]\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"images_climate_10k\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Download IG images\n",
    "class ImgSpider(scrapy.Spider):\n",
    "    name = \"img\"\n",
    "    \n",
    "    # Describe requests\n",
    "    def start_requests(self):        \n",
    "        for url in img_links:\n",
    "            req = scrapy.Request(url, self.save_img)\n",
    "            im_name = url.rsplit('/', 1)[1].rsplit('?', 1)[0]\n",
    "            p_im = os.path.join(args.out_dir, im_name)\n",
    "            req.meta[\"img_path\"] = p_im\n",
    "            yield req   \n",
    "\n",
    "    # Save images\n",
    "    # Don't use image libraries \n",
    "    # Since some formats may not be recognized\n",
    "    def save_img(self, response):\n",
    "        p_im = response.meta[\"img_path\"]\n",
    "        with open(p_im, \"wb\") as fout:\n",
    "            # Body of page is image data\n",
    "            fout.write(response.body)    \n",
    "        \n",
    "\n",
    "# Be polite! Set a download delay, in seconds.\n",
    "# Reduce/increase concurrent requests if needed\n",
    "# Set settings and run spider\n",
    "# TODO - autothrottle\n",
    "# THings to explore- \n",
    "# 1. Autothrottle 2. Pipelines 3. Writing to database 4. Xpath 5. Infinite scrolling\n",
    "img_settings = {\n",
    "                    \"BOT_NAME\": 'igimg',\n",
    "                    \"LOG_LEVEL\": \"WARNING\",\n",
    "                    \"USER_AGENT\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.81 Safari/537.36',\n",
    "                    \"ROBOTSTXT_OBEY\": True,\n",
    "                    \"CONCURRENT_REQUESTS\": 32,\n",
    "                    \"DOWNLOAD_DELAY\": 1.5\n",
    "                }                \n",
    "\n",
    "img_process = CrawlerProcess(settings=img_settings)\n",
    "img_process.crawl(ImgSpider)\n",
    "img_process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3urGRE4BIJKB"
   },
   "source": [
    "### Data Cleaning\n",
    "\n",
    "The first step in our modeling technique is the essential step in the Exploratory Data Analysis pipeline, the data cleaning methods. Data collected using our scraper was obatined in an unstructured text file format, which required conversion to a structured data format and additional cleaning to seggregate hashtags for further analysis. We achieved this by converting the unstructured text data to a json file, and the objects within the json file represented name-value pairs of the following fields:\n",
    "1. media_id: A unique number of the post on Instagram\n",
    "2. shortcode: Shortcode for the tinyurl\n",
    "3. timestamp: Unix timestamp on when the content was posted\n",
    "4. captions: The caption of the post\n",
    "5. hashtags: The hashtags used with that post\n",
    "6. num_comments: The total number of comments \n",
    "7. num_likes: The total number of likes\n",
    "8. post_link: The link to the post on Instagram\n",
    "9. media_link: The link to only the image, story, or video on Instagram (without meta-data for that post)\n",
    "10. media_type: Type of post - Image, Video, Story(known as sidecar)\n",
    "11. account_id: The unique account id on Instagram for the user who posted this content.\n",
    "\n",
    "After the data was converted in json format for easy parsing and analysis, the follwing additional cleaning techniques were deployed:\n",
    "1. First step achieved was to filter the data to only retain media which were images. This was done as our objective is to analyze how users post images on Instagram and use image embeddings to accomplish the objective. \n",
    "2. Secondly, the filtered Images were processed further to remove redundant hashtags like \"ClimateChange\" which were representative of the hashtag \"climatechange\". \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting posts to embeddings\n",
    "\n",
    "We converted the images to image embeddings using the VGGnet and the captions (cleaned by removing emojis, hashtag symbols etc) to sentence embeddings using a 16-language text encoder (https://tfhub.dev/google/universal-sentence-encoder-multilingual/2). Some of the code for converting to image embeddings is shown below. The notebook for this code is present separately on the repo. The code for sentence embeddings was similar but much simpler, as we simply has to query the TensorFlowHub API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(299),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "print(list(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = '/content/gdrive/My Drive/Fall_2019/Data science/Project/Climate_scrape/images_climate_10k'\n",
    "\n",
    "im_names = []\n",
    "\n",
    "images = []\n",
    "\n",
    "listdirs = os.listdir(im_dir)\n",
    "\n",
    "num_pics = len(listdirs)\n",
    "lists = []\n",
    "\n",
    "for i in range(num_pics // 500 + 1):\n",
    "  lo = i * 500\n",
    "  hi = (i+1) * 500\n",
    "  if(i == num_pics//500):\n",
    "    hi = num_pics\n",
    "  lists.append(listdirs[lo:hi])\n",
    "\n",
    "for l in lists:\n",
    "  print(len(l))\n",
    "\n",
    "# lists = [listdirs[:1000], listdirs[1000:2000], listdirs[2000:3000], listdirs[3000:4000], \n",
    "#         listdirs[4000:5000], listdirs[5000:6000], listdirs[6000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_list, listdir in enumerate(lists):\n",
    "  print(f\"List {num_list}\")\n",
    "  n = len(listdir)\n",
    "  print(f\"Num of elements = {n}\")\n",
    "  input_batch = np.zeros([n, 3, 299, 299])\n",
    "  for i, name in enumerate(listdir):\n",
    "    if((i+1) % 100 == 0):\n",
    "    \tprint(f\"Iteration {i+1}\")  \t  \t\n",
    "    im_path = os.path.join(im_dir, name)\n",
    "    im_names.append(im_path)    \n",
    "    with Image.open(im_path) as im:  \n",
    "  \t  if(im.mode != \"RGB\"):\n",
    "  \t  \tim = im.convert(\"RGB\")\n",
    "  \t  it = preprocess(im)\n",
    "  \t  input_batch[i, :] = np.array(it)\n",
    "\n",
    "  input_batch = torch.tensor(np.stack(input_batch, axis=0), dtype=torch.float32)\n",
    "  print(input_batch.shape)\n",
    "  # second_m = torch.nn.Sequential(*list(model.children()))\n",
    "\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      input_batch = input_batch.to('cuda')\n",
    "      model.to('cuda')\n",
    "\n",
    "\n",
    "  list_outputs = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for i in range(n // 64):\n",
    "      if((i+1) % 20 == 0):\n",
    "        print(f\"Batch {i+1}\")\n",
    "      lo = i*64\n",
    "      hi = (i+1) * 64\n",
    "      if(i == n//64 - 1):\n",
    "        hi = n\n",
    "      output2 = model.features(input_batch[lo:hi]) \n",
    "      output3 = model.avgpool(output2) \n",
    "      output3 = torch.flatten(output3,1)   \n",
    "      list_outputs.append(model.classifier[:4](output3))\n",
    "  \n",
    "  list_outputs = [np.array(arr.cpu()) for arr in list_outputs]\n",
    "  print(len(list_outputs))\n",
    "  output = np.concatenate(list_outputs)\n",
    "  list_outputs = None\n",
    "\n",
    "  embed_json = {}\n",
    "  for i, im in enumerate(listdir):\n",
    "  \tembed = list(output[i, :])\n",
    "  \tembed = [str(fl) for fl in embed]\n",
    "  \tembed_json[im] = embed\n",
    "\n",
    "  with open(f'/content/gdrive/My Drive/Fall_2019/Data science/Project/Climate_scrape/im_embed_{num_list}.json', 'w') as f2:\n",
    "  \tjson.dump(embed_json, f2, indent=4)\n",
    "\n",
    "  embed_json= None\n",
    "  input_batch = None\n",
    "  output = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbvL-qyDIJKC"
   },
   "source": [
    "### Modelling and Visualizations\n",
    "\n",
    "The objective of our project was to create groups and sub-groups of the data to characterize the images with related hashtags and sentences. The data derived had no inherent annotations to classify into categories, which called for the use of unsupervised learning techniques. Using unsupervised learning algorithms, like k-means clustering, hierarchical clustering, and DBSCAN in a two-step process we analyzed the image data and meta-data of hashtags and captions. \n",
    "\n",
    "In step 1, we first created image embeddings using a pre-trained model from pytorch, 'Inception_v3'. Inception_v3 is an image recognition model created by Google (https://pytorch.org/hub/pytorch_vision_inception_v3/) used for projects requiring image recognition. We used this model because in its 42-layer network architecture could.....\n",
    "\n",
    "#The image embeddings were then clustered using visualized using t-SNE to see how the representative groups \n",
    "\n",
    "In step 2, the captions from the Image posts were analyzed by creating vectors using sentence-embedding techniques. These vectors were classified into clusters using k-means, DBSCAN, and hierarchial clustering algorithms as shown below. After the clusters were created they were analyzed by counting the number of frequent hashtags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qObpvELlIJKC"
   },
   "source": [
    "# TSNE visualisation of KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YXUukMWIJJ3"
   },
   "outputs": [],
   "source": [
    "with open('line_embeddings.json', 'r') as f:\n",
    "  array = json.load(f)\n",
    "with open('img_embeddings.json', 'r') as f:\n",
    "  img_array = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = list(array.keys())\n",
    "img_dict = {im_name:i for i, im_name in enumerate(img_names)}\n",
    "\n",
    "textembl = [np.float32(array[key]) for key in array]\n",
    "textembl = np.array(textembl)\n",
    "keys1 = [img_dict[key] for key in array]\n",
    "array = None\n",
    "textembl=np.insert(textembl,0,keys1,1)\n",
    "#print(len(textembl),textembl[0])\n",
    "print(\"Loaded sentence embeddings\")\n",
    "\n",
    "img_embed = [np.float32(img_array[key]) for key in img_array]\n",
    "img_embed = np.array(img_embed)\n",
    "img_keys = [img_dict[key] for key in img_array]\n",
    "img_array = None\n",
    "img_embed = np.insert(img_embed, 0, img_keys, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nf_dMjjNIJKD"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(init='k-means++',  random_state = 42)\n",
    "kmeans.fit(textembl[:,1:].astype('float32'))\n",
    "ypred=kmeans.predict(textembl[:,1:].astype('float32'))\n",
    "\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(textembl.shape[1]) ]\n",
    "df = pd.DataFrame(textembl,columns=feat_cols)\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(textembl[:, 1:])\n",
    "\n",
    "df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
    "df_subset['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=ypred,\n",
    "    palette=sns.color_palette(\"hls\", 8),\n",
    "    data=df_subset,\n",
    "    # legend=\"full\",\n",
    "    alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tSNE.png\">\n",
    "tSNE visualization of sentence embeddings clustered and projected to two dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we did a hashtag distribution analysis on each such cluster, and found something very interesting. The topmost 10 hashtags in each cluster more or less followed a subjective theme. This is demonstrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/line/cat0.png\">\n",
    "Theme is environment and sustainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/line/cat1.png\">\n",
    "Theme is climate activism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/line/cat2.png\">\n",
    "Theme is nature photography."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/line/cat3.png\">\n",
    "Theme is eco-friendliness measures like recycling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/line/cat4.png\">\n",
    "This is kind of a mixed bag, but it includes food related hashtags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/line/cat5.png\">\n",
    "This is talking about climate crisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/line/cat6.png\">\n",
    "This is again mixed but some themes identified are lgbtq and feminism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/line/cat7.png\">\n",
    "This focuses VERY prominently on veganism, despite the actual share of vegan marked tweets being quite low. In fact, vegan related hashtags did not even come up when this clustering analysis was done with image embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried this same analysis using image embeddings, but the topmost hashtags in each category discovered by KMeans were all almost the same throughout the groups. There was no meaningful discovery of important groups of posts using image embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oyoyjPsCIJKH"
   },
   "source": [
    "# Hierarchical Clustering - Dendograms (based on sentence embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8KxxSyYIJKI"
   },
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Posts classification\")\n",
    "dend = shc.dendrogram(shc.linkage(textembl[:,1:].astype('float32'), method='ward'),show_leaf_counts=True,truncate_mode='lastp',\n",
    "    show_contracted=True)\n",
    "plt.axhline(y=11.5, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dendo.png\">\n",
    "Dendrogram doesnot provide a single partitioning of the data set, but instead persents an extensive hierarchy of clusters that merge with each other at certain distances. In a dendrogram, the y-axis marks the distance at which the clusters merge. Based on the distances, the dendrogram was understood to be partitioning the data into 4 groups. The last p non-singleton clusters formed in the linkage are the only non-leaf nodes in the linkage, and all other non-singleton clusters are contracted into leaf nodes. The linkage method ward is used which minimizes the variance of the clusters being merged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VI104MjeIJKK"
   },
   "source": [
    "### Results\n",
    "\n",
    "We discovered that clustering using sentence embeddings is most helpful to analyze instagram posts for the hashtag climatechange, and the images carried little to no meaning. Indeed, the images, on visual inspection, were found to be very random, consisting of stock photos, activists, memes or posters, often unrelated to the caption, which held the real message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "beqb6_T4IJKL"
   },
   "source": [
    "### Conclusions and Future Work\n",
    "Through our analysis, we attempted to examine publicly available 10,000 Instagram image posts related which used the hashtag climatechange. Our analysis showed how myriad of images posted on Instagram with this hashtag does not categorize into the domain of climate change science. We purposefully chose this particular hashtag to do our analysis, as climatechange is one of the recurring trending topics and it was interesting to examine how users apply this hashtag to their posts. Initially our hypothesis was that relevant images may be using this hashtag, although co-occuring gobbledygook hashtags along with climate change was expected. This was because the trending hashtags which are often used to make a post popular are random words like “follow4follow”, “fun”, “instalike” etc. (https://www.all-hashtag.com/top-hashtags.php). Instead it was found that, no key takeaways could be derived from image clusters due to the plethora of different images posted on Instagram. Whereas, clusters of sentence-embeddings derived from the captions contained similar subjective-domains related to climate change, like hashtags that advocated climate change action were clustered together, and hashtags that highlighted veganism were grouped together. Thus, it can be concluded that the text data like captions, and hashtags are much more helpful in characterizing the topic. \n",
    "\n",
    "To understand user behavior in depth on Instagram, some other techniques of exploration can be adopted in future:\n",
    "1. The data scraped contained total number of comments, total number of likes, total number of organic + sponsored likes (applicable only to Business profiles on Instagram, which promote the post to get more popular). This data can be leveraged to check which hashtags within each cluster of sentence-embeddings led to more number of comments and likes.\n",
    "\n",
    "2. The data collected in our study was limited to 10,000 posts, due to technical complexity posed by the scraper used, and Instagram’s privacy policy. Sophisticated methods can be used in future to extract more posts. More data will help in training the models better to do the clustering analysis. This might often not be true for other Data Science problems, but in our case, the data extracted spanned over two days and often topics like climate change have increased posts based on public outcry, and thus collecting more data will be helpful.\n",
    "3. Furthermore, analyzing user behavior on Instagram should not be limited to data derived for a particular hashtag. Instead data for multiple hashtags or location specific data should be extracted to analyze which ‘categories’ (again clusters of image posts) trend in a particular region or for a group of co-occurring hashtags."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "finalReport.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
